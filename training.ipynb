{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True,padding=\"max_length\")\n",
    "\n",
    "    # Setup the tokenizer for the targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=128, truncation=True,padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "tokenized_datasets = dataset.map(preprocess_data, batched=True, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import torch\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5-summarization\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True, \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    ")\n",
    "\n",
    "# Define data collator\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(int(0.5*len(dataset[\"train\"])))),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: rouge_score in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: click in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: absl-py in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: numpy in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\be notes\\project ppt & report\\t5-text\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk rouge_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: 0.5333333333333332\n",
      "rouge2: 0.35616438356164376\n",
      "rougeL: 0.45333333333333337\n",
      "rougeLsum: 0.45333333333333337\n"
     ]
    }
   ],
   "source": [
    "import evaluate \n",
    "from transformers import pipeline \n",
    "from datasets import load_from_disk \n",
    " \n",
    "# Load the fine-tuned model \n",
    "summarizer = pipeline(\"summarization\", model=\"./t5-summarization\", device=0) \n",
    "rouge = evaluate.load(\"rouge\") \n",
    " \n",
    "dataset =load_from_disk(\"./tokenized_cnn_dailymail/test/\") \n",
    "dat=dataset.select(range(8000)) \n",
    " \n",
    "generated_summaries = [] \n",
    "reference_summaries = [] \n",
    " \n",
    "for sample in dat: \n",
    "    generated_summary = summarizer(sample[\"article\"], max_length=74, min_length=20, num_beams=4) \n",
    "    generated_summaries.append(generated_summary[0][\"summary_text\"]) \n",
    "    reference_summaries.append(sample[\"highlights\"]) \n",
    " \n",
    "# Compute ROUGE \n",
    "results = rouge.compute(predictions=generated_summaries, references=reference_summaries) \n",
    " \n",
    "# Display ROUGE scores \n",
    "for key, value in results.items(): \n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./ft5-summarization\")\n",
    "tokenizer.save_pretrained(\"./t5-summarization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
